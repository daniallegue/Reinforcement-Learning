{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE2530 Computational Intelligence\n",
    "## Assignment 3: Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Fill in your group number **from Brightspace**, names, and student numbers._\n",
    "    \n",
    "| Group                   | 65      |\n",
    "|-------------------------|---------|\n",
    "| Daniel De Dios          | 5722055 |\n",
    "| Ignacio Cuñado Barral   | 5716128 |\n",
    "| Pablo Hendriks Bardaj   | 5790069 |\n",
    "| Alberto Moreno Sanchez  | 5688078 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T17:06:58.984211300Z",
     "start_time": "2024-03-28T17:06:57.460578900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\PycharmProjects\\dentistry-ai\\venv\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\danie\\PycharmProjects\\dentistry-ai\\venv\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\danie\\PycharmProjects\\dentistry-ai\\venv\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You may only use numpy to implement your algorithms\n",
    "You can make use of any other libraries for miscellaneous functions, e.g. to create the visual aids.\n",
    "Put all of your imports in this code block.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"\n",
    "The following classes are fully implemented in their own files and you should not change them.\n",
    "Nonetheless, we encourage you to check how they work; this will help you get started.\n",
    "\"\"\"\n",
    "from Agent import Agent\n",
    "from Maze import Maze\n",
    "from QTable import QTable\n",
    "from State import State\n",
    "from Action import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Navigating in the Supermarket\n",
    "### 2.1 Development\n",
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T17:07:01.955890800Z",
     "start_time": "2024-03-28T17:07:01.925089100Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExplorationStrategy:\n",
    "    def __init__(self, q_table: QTable):\n",
    "        self.q_table = q_table\n",
    "\n",
    "    def random(self, agent: Agent, maze: Maze):\n",
    "        \"\"\"\n",
    "        The random exploration strategy selects a random action uniformly at random\n",
    "        from the set of all valid actions.\n",
    "        \"\"\"\n",
    "        valid_actions = agent.get_valid_actions(maze)\n",
    "        selected_action = random.choice(valid_actions)\n",
    "\n",
    "        return selected_action\n",
    "\n",
    "    def e_greedy(self, agent: Agent,  maze: Maze, eps: float):\n",
    "        \"\"\"\n",
    "        The e-greedy exploration strategy selects a random action with probability eps,\n",
    "        and the action with highest q-value with probability 1 - eps. A value of epsilon\n",
    "        close to 0 favours exploitation, while a value close to 1 favours exploration.\n",
    "        \"\"\"\n",
    "        if random.uniform(0, 1) < eps:\n",
    "            # Explore\n",
    "            valid_actions = agent.get_valid_actions(maze)\n",
    "            selected_action = random.choice(valid_actions)\n",
    "        else:\n",
    "            # Exploit\n",
    "            current_state = agent.get_state(maze)\n",
    "            q_values = self.q_table.q_table[current_state.id]\n",
    "            max_q = max(q_values.values())\n",
    "            # Find all actions with the max q-value\n",
    "            best_actions = [action_id for action_id, q in q_values.items() if q == max_q]\n",
    "            # Randomly choose among the best actions in case there's a tie\n",
    "            selected_action_id = random.choice(best_actions)\n",
    "            # Assuming you have a method or a way to convert an action ID back to an Action object\n",
    "            selected_action = Action(id=selected_action_id)  # You need to adjust this part\n",
    "\n",
    "        return selected_action\n",
    "\n",
    "\n",
    "    def boltzmann(self, agent: Agent, maze: Maze, temperature: float):\n",
    "        \"\"\"\n",
    "        The Boltzmann exploration strategy assigns a probability to each action based on its estimated q-values.\n",
    "        A large value of the temperature encourages exploration, and as the temperature declines over time,\n",
    "        exploitation is favoured. \n",
    "        \"\"\"\n",
    "        current_state = agent.get_state(maze)\n",
    "        q_values = self.q_table.q_table[current_state.id]\n",
    "        \n",
    "        # Get probabilities from q-values\n",
    "        probabilities = np.array([np.exp(q / temperature) for q in q_values.values()])\n",
    "        probabilities /= probabilities.sum()\n",
    "        \n",
    "        action_list = list(q_values.keys())\n",
    "        selected_action_id = np.random.choice(action_list, p=probabilities)\n",
    "        \n",
    "        selected_action = Action(id=selected_action_id) \n",
    "        \n",
    "        return selected_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your extra code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T17:10:10.744153900Z",
     "start_time": "2024-03-28T17:10:09.728393700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 298.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a Maze instance.\n",
    "maze = Maze(\"./../data/toy_maze.txt\")\n",
    "maze.set_reward(x=9, y=9, reward=10)\n",
    "maze.set_terminal(x=9, y=9)\n",
    "# Create an Agent.\n",
    "agent = Agent(start_x=0, start_y=0)\n",
    "# Create a QTable.\n",
    "states = maze.get_all_states()\n",
    "actions = [Action(id) for id in [\"up\", \"down\", \"left\", \"right\"]]\n",
    "q_table = QTable(states, actions)\n",
    "# Create an ExplorationStrategy.\n",
    "exploration_strategy = ExplorationStrategy(q_table)\n",
    "# Create a learner.\n",
    "params = {\"lr\": 0.7, \"gamma\": 0.9}\n",
    "# learner = QLearning(q_table, params)\n",
    "\n",
    "# Hyper-parameters.\n",
    "n_episodes = 300\n",
    "episode_lengths = []\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in tqdm(range(n_episodes)):\n",
    "    total_reward = 0\n",
    "    agent.reset()  \n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    while not done:\n",
    "        current_state = agent.get_state(maze)\n",
    "        action = exploration_strategy.random(agent, maze)  # Adjust epsilon as needed\n",
    "        next_state, reward, done = agent.step(action, maze)\n",
    "        \n",
    "        # Update the total reward\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "    episode_rewards.append(total_reward)\n",
    "    episode_lengths.append(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your extra code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your extra code blocks above (if any) and write your answer here._  \n",
    "_You may want to directly modify the cycle in Question 2._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "\n",
    "    def __init__(self, q_table: QTable, params: Dict[str, float]) -> None:\n",
    "        self.q_table = q_table\n",
    "        self.params = params\n",
    "\n",
    "    def learn(self, possible_actions: List[Action], state: State, action: Action,\n",
    "               next_state: State, reward: int, done: bool) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSA:\n",
    "\n",
    "    def __init__(self, q_table: QTable, params: Dict[str, float]) -> None:\n",
    "        self.q_table = q_table\n",
    "        self.params = params\n",
    "    \n",
    "    def learn(self, state: State, action: Action, next_state: State, next_action: Action,\n",
    "               reward: float, done: bool) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your extra code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Optimization\n",
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Introducing More Rewards\n",
    "#### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Put your code blocks above (if any) and write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Open Questions\n",
    "### 3.1 Reflection\n",
    "#### Question 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pen and Paper\n",
    "#### Question 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here. You can also choose to simply include a photo of your solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here. You can also choose to simply include a photo of your solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "_Write your answer here. You can also choose to simply include a photo of your solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Division of Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "\n",
    "|          Component          |  Name A   |  Name B   |  Name C   |  Name D   |\n",
    "|-----------------------------|-----------|-----------|-----------|-----------|\n",
    "| Code (design)               |     A     |     B     |     C     |     D     |\n",
    "| Code (implementation)       |     A     |     B     |     C     |     D     |\n",
    "| Code (validation)           |     A     |     B     |     C     |     D     |\n",
    "| Experiments (execution)     |     A     |     B     |     C     |     D     |\n",
    "| Experiments (analysis)      |     A     |     B     |     C     |     D     |\n",
    "| Experiments (visualization) |     A     |     B     |     C     |     D     |\n",
    "| Report (original draft)     |     A     |     B     |     C     |     D     |\n",
    "| Report (reviewing, editing) |     A     |     B     |     C     |     D     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e\">\n",
    "\n",
    "**If you made use of any non-course resources, cite them below.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
